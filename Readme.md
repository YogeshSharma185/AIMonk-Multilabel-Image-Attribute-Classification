# Aimonk Multilabel Image Attribute Classification

## ğŸ“Œ Problem Statement

This is a **multilabel image classification problem** where each image can have **multiple attributes simultaneously**.

- Each image is associated with **4 attributes**
- Label values:
  - **1** â†’ Attribute is present
  - **0** â†’ Attribute is absent
  - **NA** â†’ Attribute information is **not available** for that image

The dataset consists of:
- An `images/` directory containing image files
- A `labels.txt` file with the following format:
```text
image_0.jpg 1 NA 0 1
image_1.jpg NA 0 0 0
image_2.jpg 1 1 0 0
```
...


---

## ğŸ¯ Objective

To build a **deep learningâ€“based multilabel classification system** that:

1. Trains a model using images and labels
2. Handles missing labels (`NA`) correctly
3. Tackles dataset imbalance
4. Produces a trained model file
5. Plots training loss
6. Performs inference on new images
7. Provides a Streamlit-based UI for image upload and prediction

---

## âœ… Deliverables Implemented

âœ” Training code producing a deep learning model (`model.pth`)  
âœ” Loss curve plot  
âœ” Provides both notebook-based and UI-based inference  

---

## ğŸ§  Model Architecture

- **Backbone**: `ResNet18`
- **Pretraining**: ImageNet weights (`IMAGENET1K_V1`)
- **Training Strategy**: Fine-tuning (not training from scratch)
- **Output Layer**: Fully connected layer with 4 outputs (one per attribute)

---

## ğŸ§© Handling Missing Labels (`NA`)

- `NA` values are **not ignored**
- They are encoded as `-1`
- During training:
  - A **mask** is applied to exclude `NA` values from loss computation
  - Valid labels (`0` or `1`) still contribute to training
- This ensures **maximum data utilization** without introducing noise

---

## âš–ï¸ Handling Dataset Imbalance

The dataset is **skewed**, with unequal distribution of positive labels per attribute.

### Technique Used:
- **Attribute-wise positive class weighting**
- Computed using:
pos_weight = (total_samples - positive_samples) / positive_samples

- Applied using `BCEWithLogitsLoss(pos_weight=...)`

This penalizes the model more for misclassifying rare attributes.

---

## ğŸ§ª Training Details

- **Framework**: PyTorch
- **Loss Function**: Binary Cross Entropy with Logits
- **Optimizer**: Adam
- **Batch Size**: 16
- **Epochs**: 20
- **Learning Rate**: 1e-4
- **Device**: GPU (if available), else CPU

During training:
- Batch-level progress is shown using `tqdm`
- Epoch time and ETA are displayed
- Training loss is recorded per iteration

---

## ğŸ“ˆ Loss Curve

- X-axis: `iteration_number`
- Y-axis: `training_loss`
- Title: `Aimonk_multilabel_problem`

This plot helps visualize convergence and training stability.

ğŸ“¸ **Screenshot placeholder**:
![alt text](image-2.png)


---

## ğŸ” Inference

This project supports **two inference methods**, allowing flexibility for both experimentation and deployment:

### 1.Notebook Inference
- Input: Image path
- Output: List of predicted attributes

Example:
```python
predict("images/image_0.jpg")
```
Output:
```python
Image: image_0.jpg
Attributes present: ['Attr1', 'Attr4']
```

---


## 2.Streamlit Web Application
### A Streamlit-based UI is also provided for easy inference.###

- Features:
- Upload an image

- Adjustable prediction threshold

- Fixed image display size

- Attribute predictions with confidence scores

- Clean, professional layout

- Run the app:
```python
streamlit run app.py
```
- ğŸ“¸ Screenshot placeholders:
![alt text](image.png)
![alt text](image-1.png)


---


## ğŸ“ Project Structure
```text
project/
â”‚
â”œâ”€â”€ images/                # Input images
â”œâ”€â”€ labels.txt             # Image labels
â”œâ”€â”€ model.pth              # Trained model weights
â”œâ”€â”€ streamlit.py           # Streamlit inference app
â”œâ”€â”€ train.ipynb            # Training & inference notebook
â”œâ”€â”€ logo.jpg               # Project logo
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---


## ğŸ“¦ Requirements
### Key dependencies:###

- torch

- torchvision

- matplotlib

- pillow

- tqdm

- streamlit

- (Full list available in requirements.txt)


---


## ğŸ Conclusion
### This project successfully implements a robust multilabel image attribute classification system that:###

- Uses transfer learning

- Handles missing labels properly

- Addresses dataset imbalance

- Provides both notebook-based and UI-based inference

- Is modular, clean, and production-ready


---


## ğŸ‘¤ Author
- **Yogesh Sharma**
Machine Learning / Deep Learning Practitioner


---
